{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043957ad-a7ed-4121-ab51-bf7798f4ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML   \n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 98% !important; }</style>\"))\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52fbdd6-10c5-4f52-b015-ce0f812c7d94",
   "metadata": {},
   "source": [
    "# Pattern Matching on AMD's stock price action\n",
    "\n",
    "This notebook shows pattern matching on AMD's stock price using L2 similarity search on KDB.AI. \n",
    "\n",
    "### Goals \n",
    "\n",
    "1. Load Data\n",
    "1. Create Vector Embeddings\n",
    "1. Store Embeddings in KDB.AI\n",
    "1. Search For Similar Sequences To A Target Sequence\n",
    "1. Delete the KDB.AI Table\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea686a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import Modules\n",
    "\n",
    "import os, time\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_ta         as ta     ## For VWAP calculation \n",
    "import kdbai_client      as kdbai\n",
    "from   utils             import *  ## Import plotting functions\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc7dba-21ff-4be6-a3a5-611920e44e10",
   "metadata": {},
   "source": [
    "### Connect to KDB.AI Session\n",
    "\n",
    "To use KDB.AI, you will need two session details - a URL endpoint and an API key. \n",
    "To get these you can sign up for free [here](https://trykdb.kx.com/kdbai/signup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404274bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Create \".env\" file from  \"env_copy.text\"\n",
    "\n",
    "from os.path import join,dirname\n",
    "from dotenv  import load_dotenv\n",
    "\n",
    "# dotenv_path = join(dirname, './.env')\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# lazy auth    -- just enter info.. \n",
    "# endpoint          ='XXXX.kdb.ai' \n",
    "# api_key1          ='YOUR_KDBAI_API_KEY'\n",
    "\n",
    "KDBAI_ENDPOINT  = os.environ.get(\"endpoint\") \n",
    "KDBAI_API_KEY1  = os.environ.get(\"api_key1\")\n",
    "\n",
    "## Sanity Check \n",
    "# print(KDBAI_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965c3fd-c979-4d8f-ae4a-9c5652e60d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session early, check table on your instance\n",
    "session = kdbai.Session(api_key=KDBAI_API_KEY1, endpoint=KDBAI_ENDPOINT)\n",
    "print(session.list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d03b85",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff66c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(df.shape)\n",
    "    return display(df.head(3))\n",
    "\n",
    "def TableCheckDrop(t):\n",
    "    if t in session.list():\n",
    "        session.table(t).drop()\n",
    "        time.sleep(2)\n",
    "        print (\"Table found: Dropped, safe to add:\", t) \n",
    "    else: print (\"No Table found: Safe to add:\", t) \n",
    "\n",
    "def timeSliceData(t1,t2,dataSlice1=pd.DataFrame,dataSliceOpn=pd.DataFrame()):\n",
    "    dataP_     = dataSlice1.between_time(t1[0],t1[1]).pivot(index='Date', columns='Time', values='Close'); \n",
    "    dataP__    = dataSlice1.between_time(t2[0],t2[1]).pivot(index='Date', columns='Time', values='Close');\n",
    "\n",
    "    dataP_     = dataP_.div(dataSliceOpn.values, axis=0)\n",
    "    dataP__    = dataP__.div(dataSliceOpn.values,axis=0)\n",
    "\n",
    "    dataP_V    = dataSlice1.between_time(t1[0],t1[1]).pivot(index='Date', columns='Time', values='VWAP')\n",
    "    dataP__V   = dataSlice1.between_time(t2[0],t2[1]).pivot(index='Date', columns='Time', values='VWAP')\n",
    "\n",
    "    dataP_V    = dataP_V.div(dataSliceOpn.values, axis=0)\n",
    "    dataP__V   = dataP__V.div(dataSliceOpn.values, axis=0)\n",
    "\n",
    "    IdxMap     = dataP_.reset_index()[\"Date\"].astype('str').to_dict()\n",
    "\n",
    "    global findIndex\n",
    "    def findIndex(value): return next((k for k,v in IdxMap.items() if v == value), None)\n",
    "    # findIndex('2021-12-01')\n",
    "\n",
    "    global findDate\n",
    "    def findDate(value): return IdxMap[value]\n",
    "    #findDate(240)\n",
    "\n",
    "    return dataP_, dataP__, dataP_V, dataP__V,  IdxMap      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a721fcf-01b2-4f46-bf2d-7c22926b5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for data\n",
    "# !ls ../data/\n",
    "# !ls ../images/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51a1fc5-ad24-4107-81e1-507137d62280",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "\n",
    "The dataset containing AMD stock prices from January 4th, 2021, to March 1st, 2024, with data points recorded between \n",
    "8:00 and 15:00. Additionally, we have preprocessed and cleaned the data for smooth operation in a notebook aimed at \n",
    "developers. We chose this time period as we believe that ODTE was influencing the stock and will continue to do so. \n",
    "We made a decision that this notebook will not be quantative rigorous. We have look ahead bias and other errors. \n",
    "Users can tailor the analysis to their specific needs and preferences.\n",
    "\n",
    "Added columns to Open, High, Low, Close, Volume data \n",
    "- _symIDT   = Symbol, Date, Time \n",
    "- HL2       = (High+ Low)/2\n",
    "- DOW       = Day of Week\n",
    "- RF        = Thursday or Friday\n",
    "- WOM       = Week of Month\n",
    "- OpExRF    = OpEx Thursday or Friday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440fadc9-7b3b-4d4b-8293-f1c8eace2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read directly from the zip file.#\n",
    "dataPrep              = pd.read_csv(\"../data/AMD_dataPrep.csv.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e584484f",
   "metadata": {},
   "source": [
    "### Process The Data\n",
    "\n",
    "Create two dataframes:\n",
    "\n",
    "- OHLC DataFrame \n",
    "- Filters DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6a77c-6ab7-44ab-959a-9de9f9a346c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols                  = [\"TStamp\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]\n",
    "dataSlice1            = dataPrep[cols].copy()\n",
    "\n",
    "dataSlice1[\"TStamp\"]  = dataSlice1[\"TStamp\"].astype('datetime64[s]')\n",
    "dataSlice1['Date']    = pd.to_datetime(dataSlice1[\"TStamp\"].dt.date)\n",
    "dataSlice1['Time']    = dataSlice1[\"TStamp\"].dt.time\n",
    "dataSlice1            = dataSlice1.set_index(\"TStamp\") \n",
    "dataSlice1['VWAP']    = ta.vwap(dataSlice1['High'], dataSlice1['Low'], dataSlice1['Close'], dataSlice1['Volume'], anchor=\"D\")\n",
    "dataSlice1            = dataSlice1.between_time('9:30','15:59')\n",
    "# print(dataSlice1.head(3)\n",
    "\n",
    "dataSliceOpn          = dataSlice1.between_time('9:30','9:30')[\"Open\"]\n",
    "# dataSliceOpn.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f036a3-7984-46bf-9994-ee64da19e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols                  = ['Symbol', 'TStamp', 'DOW', 'RF', 'WOM', 'OpExRF']\n",
    "filtersData           = dataPrep[cols].copy()\n",
    "\n",
    "filtersData[\"TStamp\"] = filtersData[\"TStamp\"].astype('datetime64[s]')\n",
    "filtersData['Date']   = pd.to_datetime(filtersData[\"TStamp\"].dt.date)\n",
    "filtersData           = filtersData.set_index(\"TStamp\").between_time('9:30','9:30').set_index(\"Date\")\n",
    "# filtersData.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f0b8a-5b48-476b-b33d-d2070a4953ea",
   "metadata": {},
   "source": [
    "### Select The Time Windows And Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae027e-753b-43de-9a51-fe0096ea194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Select Time Tuples from \n",
    "##  Use 0,1 for mapped ('9:30','9:59:59'),                    and projected ('9:30','12:29:59')\n",
    "##  Use 1,2 for mapped ('9:30','12:29:59')                    and projected ('9:30','15:59:59')\n",
    "##  Use 3,1 for mapped ['9:45','10:29:59',\"<<--custom time\"]  and projected ('9:30','12:29:59')\n",
    "\n",
    "mapped                = 0   ## mapped time period  \n",
    "projected             = 1   ## projected time period \n",
    "\n",
    "#### adjust           ['9:45','10:29:59',\"<<--custom time\"] for custom time periods\n",
    "tPeriod               = [('9:30','9:59:59'),('9:30','12:29:59'),('9:30','15:59:59'),['9:45','10:29:59',\"<<--custom time\"] ][mapped]\n",
    "tPeriod2              = [('9:30','9:59:59'),('9:30','12:29:59'),('9:30','15:59:59'),['9:59','15:59:59',\"<<--custom time\"] ][projected]\n",
    "\n",
    "# Run function to create pivot tables\n",
    "periodData            = timeSliceData(tPeriod,tPeriod2,dataSlice1,dataSliceOpn)\n",
    "\n",
    "## Price and VWAP Pivot Tables \n",
    "P_,    P_Proj         = periodData[0], periodData[1]\n",
    "PVWAP ,PVWAPProj      = periodData[2], periodData[3]\n",
    "\n",
    "\n",
    "## Inputs for KDB.AI using HNSW and L2 similarity\n",
    "## vecs object is the vector embeddings.\n",
    "Date_                 = P_.index              ## Dates\n",
    "vecs                  = P_.values.tolist()    ## vectors\n",
    "dims                  = len(vecs[0])          ## dims for schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e338bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the two dataframes\n",
    "embeddingsDF = pd.DataFrame({\"date\":    pd.to_datetime(Date_), \n",
    "                             \"sym\":     filtersData[\"Symbol\"].values.tolist(), \n",
    "                             \"DOW\":     filtersData[\"DOW\"].values.astype('int32').tolist(),  \n",
    "                             \"RF\":      filtersData[\"RF\"].values.astype('int32').tolist(), \n",
    "                             \"WOM\":     filtersData[\"WOM\"].values.astype('int32').tolist(),\n",
    "                             \"OpExRF\":  filtersData[\"OpExRF\"].values.astype('int32').tolist(), \n",
    "                             \"vectors\": vecs})\n",
    "\n",
    "# embeddingsDF.info() ### shows dtypes as int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372f029-25d5-47f3-90c1-49a3f1f484bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check embeddings\n",
    "show_df(embeddingsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c0b1d1",
   "metadata": {},
   "source": [
    "### Define Vector DB Table Schema\n",
    "\n",
    "The next step is to define a schema for our KDB.AI table where we will store our embeddings. Our table will have seven colums: date, sym, DOW, RF, WOM, OpExRF, and vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4438ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create schema for KDB.AI cloud instance \n",
    "## Notice the similiarities to DataFrame construction  and \"*DataFrame*\".info()\n",
    "stockSchema = {'columns': [{'name': 'date',      'pytype': 'datetime64[ns]', },\n",
    "                            {'name': 'sym',      'pytype':  'str',  },\n",
    "                            {'name': 'DOW',      'pytype': 'int32', },\n",
    "                            {'name': 'RF',       'pytype': 'int32', },\n",
    "                            {'name': 'WOM',      'pytype': 'int32', },\n",
    "                            {'name': 'OpExRF',   'pytype': 'int32', },\n",
    "                            {'name': 'vectors',  'vectorIndex': {'dims': dims, 'metric': 'L2', 'type': 'hnsw'}, },]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e345361-a3b3-4d59-bca1-0c0c6f63f910",
   "metadata": {},
   "source": [
    "### Create Vector DB Table\n",
    "\n",
    "Use the KDB.AI `create_table` function to create a table that matches the defined schema in the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1201d163-92cb-4a38-94b4-22edb2745b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Drop table from cloud instance. This does not need to done if you are going to reuse the table. \n",
    "# In this notebook, we follow the practice of dropping table after use. \n",
    "TableCheckDrop(\"Stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151df13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = session.create_table(\"Stock\", stockSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f489316",
   "metadata": {},
   "source": [
    "### Add Embedded Data to KDB.AI Session Table \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f7e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the size of data. \n",
    "embeddingsDF.memory_usage(deep=True).sum()/(1024**2)  # Convert bytes to MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce03a4fe",
   "metadata": {},
   "source": [
    "Since embeddings are small <10MB, we will insert without chunking.  See others KDB.AI examples if greater than 10MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b185eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the data has been inserted using the method table.query() which shows us that data has been added without errors\n",
    "# Sanity check raw Query\n",
    "table.insert(embeddingsDF)\n",
    "show_df(table.query())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019572d9",
   "metadata": {},
   "source": [
    "### Search KDB.AI Based on this Example Pattern\n",
    "\n",
    "We can extract the vectors from the example window selected above into a `query_vector` and search the vector database to get the five nearest other windows to this pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31c9c1-18b6-4f96-9734-e076d9abdf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## With vectors mapped, uploaded and indexed, you can search for dates. We primarly use HNSW index values to select days \n",
    "## This notebook can be is easily modified to explore unseen data. \n",
    "## Since we are filtering after uploading and indexing, the index value shouldn't change.\n",
    "## If we instead filtered prior to uploading and indexing, the index value will change. \n",
    "## Sanity Check \n",
    "print(findIndex('2021-12-15'))\n",
    "print(findDate(650))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c2d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This target is search vector. This can be replace with data that isn't in the embeddings vector uploaded.\n",
    "# If new unseen vectors are used, some of the refDates calculation will need to be modified.  \n",
    "findVector   = [vecs[650]]\n",
    "# print(findVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b9e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  \"findVector\" from above , \"n=9\" the number of nearest neighbors, we have requested nine. \n",
    "matchedVectors = table.search(findVector, n=9)\n",
    "\n",
    "## We can use filter or multiple filters after indexing. (N.B. We can also pre-filter data prior to uploading and indexing). \n",
    "# matchedVectors = table.search(findVector, n=9, filter=[(\"<>\", \"WOM\", 3)])\n",
    "# matchedVectors = table.search(findVector, n=9, filter=[(\"=\", \"OpExRF\", 0)])\n",
    "display(matchedVectors[0].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ebaa2-bc95-456c-9f08-2e5fe16c876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates      = pd.DataFrame(matchedVectors[0][\"date\"]);\n",
    "refDates   = dates[\"date\"].dt.date.astype('str'); \n",
    "# matchedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da5538-5b81-4d03-af77-eacecdd9f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the data. This is the single axis version of the plot.\n",
    "\n",
    "title = \"Indexed Price Data - Single Axis for %s\"  % (refDates[0])\n",
    "P_.loc[refDates[0]].plot(color='black', title= title,label=\"Close Data\" )\n",
    "P_.loc[refDates[1:]].mean().plot(label=\"NN Mean Close Prices\")\n",
    "PVWAP.loc[refDates[0]].plot(color='green',label=\"VWAP\").legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e060f-6f13-430e-8dd3-2590c360f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the dual axes version of the plot. There sometimes a better visual display of the data.\n",
    "\n",
    "p1date      = P_.loc[refDates[0]].index.astype(str) \n",
    "p1data      = P_.loc[refDates[0]].values\n",
    "p1Vdata     = PVWAP.loc[refDates[0]].values\n",
    "p2data      = P_.loc[refDates[1:]].mean().values\n",
    "\n",
    "title       = \"Indexed Price Data - Dual Axes\"\n",
    "plot2Axes(p1date,p1data,p2data,p1Vdata,refDates[0],title,\"window\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbefb2e-f985-4a1a-b1f8-58cb538dffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Plot the projected data based on NN's. This is the single axis version of the plot. We projecting using the mean data from the nine NN\n",
    "## \n",
    "\n",
    "title = \"Projected Indexed Price Data - Single Axis for %s\" % (refDates[0])\n",
    "P_Proj.loc[refDates[0]].plot(color='brown', title=title,label=\"Close Data\")\n",
    "P_Proj.loc[refDates[1:]].mean().plot(label=\"NN Mean Close Prices\")\n",
    "PVWAPProj.loc[refDates[0]].plot(color='green',label=\"VWAP\").legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b6072-cd79-49d2-852f-d0cdcbbd19db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the projected data based on NN's. This is the dual axes version of the plot. There sometimes a better visual display of the data.\n",
    "\n",
    "Eval2date       = P_Proj.loc[refDates[0]].index.astype(str) \n",
    "Eval2data       = P_Proj.loc[refDates[0]].values\n",
    "Eval2dataM      = P_Proj.loc[refDates[1:]].mean().values\n",
    "Eval2VWAPdata   = PVWAPProj.loc[refDates[0]].values\n",
    "\n",
    "title           = \"Projected Indexed Price Data  - Dual Axes\"\n",
    "plot2Axes(Eval2date,Eval2data,Eval2dataM,Eval2VWAPdata,refDates[0],title,\"projection\" ,c = 'r-');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9c7610-11f9-46a5-80df-00a88547003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot showing the nine NN plots for the mapped (P1) time period \n",
    "P_.index     = P_.index.astype('str');\n",
    "Eval2NN      = P_.T[refDates[1:]];\n",
    "title_       = \"NN Close Prices for %s\" % (refDates[0]);\n",
    "\n",
    "Eval2NN.plot(title =title_ );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4df316-546f-4c73-a9ec-332c646fa82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot is showing the nine NN plots for the projected time period.  \n",
    "\n",
    "P_Proj.index = P_Proj.index.astype('str')\n",
    "Eval2NN      = P_Proj.T[refDates[1:]]\n",
    "title_2      = \"NN Projected Close Prices for %s\" % (refDates[0])\n",
    "# Eval2NN.legend(loc='lower right')\n",
    "Eval2NN.plot(title =title_2 ).legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bdd5d5",
   "metadata": {},
   "source": [
    "### Delete the KDB.AI Table\n",
    "\n",
    "Once finished with the table, it is best practice to drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84213681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4956c473-5180-4b9f-a715-c9eea56f9cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd80932a-6af8-40d9-91a3-9ceb67d40507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2697b7-1276-4dad-9bec-11c730b4e336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
